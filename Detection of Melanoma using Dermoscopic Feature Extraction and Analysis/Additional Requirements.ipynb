{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the datasets for the final evaluation\n",
    "\n",
    "import shutil\n",
    "\n",
    "df = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/HAM_Edited.csv\")\n",
    "mel_df = df[df.dx == 'mel']\n",
    "mel_df = mel_df.sort_values(by = 'Count')\n",
    "print(\"mel\", len(mel_df))\n",
    "combined_df = mel_df.tail(1000)\n",
    "akiec_df = df[df.dx == 'akiec']\n",
    "akiec_df = akiec_df.sort_values(by = 'Count')  #25\n",
    "combined_df = combined_df.append(akiec_df.head(50))\n",
    "print(\"akiec\", len(akiec_df))\n",
    "bkl_df = df[df.dx == 'bkl'] \n",
    "bkl_df = bkl_df.sort_values(by = 'Count')     #150\n",
    "combined_df = combined_df.append(bkl_df.head(200))\n",
    "print(\"bkl\", len(bkl_df))\n",
    "bcc_df = df[df.dx == 'bcc']\n",
    "bcc_df = bcc_df.sort_values(by = 'Count')  #70\n",
    "combined_df = combined_df.append(bcc_df.head(100))\n",
    "print(\"bcc\", len(bcc_df))\n",
    "nv_df = df[df.dx == 'nv']\n",
    "nv_df = nv_df.sort_values(by = 'Count')\n",
    "combined_df = combined_df.append(nv_df.head(550))\n",
    "print(\"nv\", len(nv_df))\n",
    "df_df = df[df.dx == 'df']\n",
    "df_df = df_df.sort_values(by = 'Count') #18\n",
    "combined_df = combined_df.append(df_df.head(50))\n",
    "print(\"df\", len(df_df))\n",
    "vasc_df = df[df.dx == 'vasc']\n",
    "vasc_df = vasc_df.sort_values(by = 'Count') #25\n",
    "combined_df = combined_df.append(vasc_df.head(50))\n",
    "print(\"vasc\",len(vasc_df))  \n",
    "print(\"all\",len(combined_df))\n",
    "\n",
    "combined_df = combined_df.sample(frac=1)\n",
    "combined_df = combined_df.sample(frac=1)\n",
    "combined_df = combined_df.sample(frac=1)\n",
    "combined_df = combined_df.sample(frac=1)\n",
    "\n",
    "mel_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/mel_df.csv\", index=False)\n",
    "akiec_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/akiec_df.csv\", index=False)\n",
    "bkl_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/bkl_df.csv\", index=False)\n",
    "bcc_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/bcc_df.csv\", index=False)\n",
    "nv_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/nv_df.csv\", index=False)\n",
    "df_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/df_df.csv\", index=False)\n",
    "vasc_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/vasc_df.csv\", index=False)\n",
    "combined_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/combined_df.csv\", index=False)\n",
    "\n",
    "for x in range(len(combined_df)):\n",
    "    try:\n",
    "        source = \"/users/chinthaka_jayatilake/Documents/Research Work/HAM/\"+combined_df[\"image_id\"][x]+\".jpg\"\n",
    "        destination = \"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/Dataset/\"+combined_df[\"image_id\"][x]+\".jpg\"\n",
    "        shutil.copyfile(source, destination)\n",
    "        if(combined_df[\"dx\"][x] == 'mel'):\n",
    "            destination = \"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/Dataset/Melanoma/\"+combined_df[\"image_id\"][x]+\".jpg\"\n",
    "            shutil.copyfile(source, destination)\n",
    "        else:\n",
    "            destination = \"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/Dataset/Non-melanoma/\"+combined_df[\"image_id\"][x]+\".jpg\"\n",
    "            shutil.copyfile(source, destination)\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)\n",
    "        \n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiating the diseases from the dataset and creating a combined dataset\n",
    "\n",
    "df = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/HAM_Edited.csv\")\n",
    "mel_df = df[df.dx == 'mel']\n",
    "print(\"mel\", len(mel_df))\n",
    "akiec_df = df[df.dx == 'akiec']\n",
    "print(\"akiec\", len(akiec_df))\n",
    "bkl_df = df[df.dx == 'bkl']\n",
    "print(\"bkl\", len(bkl_df))\n",
    "bcc_df = df[df.dx == 'bcc']\n",
    "print(\"bcc\", len(bcc_df))\n",
    "nv_df = df[df.dx == 'nv']\n",
    "print(\"nv\", len(nv_df))\n",
    "df_df = df[df.dx == 'df']\n",
    "print(\"df\", len(df_df))\n",
    "vasc_df = df[df.dx == 'vasc']\n",
    "print(\"vasc\",len(vasc_df))\n",
    "l = 100\n",
    "mel_df = mel_df.head(1000)\n",
    "selected = akiec_df.head(200)\n",
    "dataset = mel_df.append(selected)\n",
    "selected = bkl_df.head(200)\n",
    "dataset = dataset.append(selected)\n",
    "selected = bcc_df.head(200)\n",
    "dataset = dataset.append(selected)\n",
    "selected = nv_df.head(200)\n",
    "dataset = dataset.append(selected).append(df_df.head(l)).append(vasc_df.head(l))\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset = dataset.sample(frac=1)\n",
    "print(len(dataset))\n",
    "mel_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/mel_df.csv\", index=False)\n",
    "akiec_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/akiec_df.csv\", index=False)\n",
    "bkl_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/bkl_df.csv\", index=False)\n",
    "bcc_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/bcc_df.csv\", index=False)\n",
    "nv_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/nv_df.csv\", index=False)\n",
    "df_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/df_df.csv\", index=False)\n",
    "vasc_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/vasc_df.csv\", index=False)\n",
    "dataset.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/combined_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction from the images in the HAM10000 dataset\n",
    "\n",
    "df = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Finalized Dataset/HAM10000_metadata.csv\")\n",
    "df[\"True_Status\"] = check_mel(df[\"dx\"])\n",
    "df[\"Asymmetry\"] = \"\"\n",
    "df[\"Border\"] = \"\"\n",
    "df[\"Colour\"] = \"\"\n",
    "df[\"Diameter\"] = \"\"\n",
    "df[\"Globules\"] = \"\"\n",
    "df[\"Blotches\"] = \"\"\n",
    "df[\"RedAreas\"] = \"\"\n",
    "df[\"Rosettes\"] = \"\"\n",
    "df[\"RegressionStructure\"] = \"\"\n",
    "df[\"BlueWhite\"] = \"\"\n",
    "df[\"AtypicalNetwork\"] = \"\"\n",
    "df[\"Streaks\"] = \"\"\n",
    "df[\"Asymmetry_Real\"] = \"\"\n",
    "df[\"Border_Real\"] = \"\"\n",
    "df[\"Border_New\"] = \"\"\n",
    "df[\"Colour_Real\"] = \"\"\n",
    "df[\"Diameter_Real\"] = \"\"\n",
    "df[\"Border\"] = \"\"\n",
    "df[\"Width\"] = \"\"\n",
    "df[\"Height\"] = \"\"\n",
    "df[\"Perimeter\"] = \"\"\n",
    "df[\"Percentage\"] = \"\"\n",
    "\n",
    "for x in range(len(df)):\n",
    "    try:\n",
    "        fileName = \"/users/chinthaka_jayatilake/Documents/Research Work/HAM/\"+df[\"image_id\"][x]+\".jpg\"\n",
    "        image = cv2.imread(fileName)\n",
    "\n",
    "        image = removeLens(image)\n",
    "\n",
    "        image = removeHair(image)\n",
    "\n",
    "        image = removeInkPatches(image)\n",
    "\n",
    "        copy = image\n",
    "        image, con, percentage, hull, hullImage = getContour(image)\n",
    "    \n",
    "        try:\n",
    "            df[\"Percentage\"][x] = percentage\n",
    "        except Exception as e:\n",
    "            df[\"Percentage\"][x] = \"error\"\n",
    "        if(percentage == 100):\n",
    "            state = 0\n",
    "            df[\"Asymmetry\"][x] = 0\n",
    "            df[\"Perimeter\"][x] = 0\n",
    "            df[\"Asymmetry_Real\"][x] = 0\n",
    "            df[\"Border\"][x] = 0\n",
    "            df[\"Border_Real\"][x] = 0\n",
    "            df[\"Border_New\"][x] = 0\n",
    "            try:\n",
    "                brown, red, blue, white, black, result, count = detectColour(copy, con, state)\n",
    "                df[\"Colour\"][x] = result\n",
    "                df[\"Colour_Real\"][x] = count\n",
    "            except Exception as e:\n",
    "                df[\"Colour\"][x] = \"error\"\n",
    "                df[\"Colour_Real\"][x] = \"error\"\n",
    "                print(\"Colour\",e)\n",
    "            df[\"Diameter\"][x] = 0\n",
    "            df[\"Width\"][x] = 0\n",
    "            df[\"Height\"][x] = 0\n",
    "            df[\"Diameter_Real\"][x] = 0\n",
    "            try:\n",
    "                result = detectGlobules(copy, con)\n",
    "                df[\"Globules\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Globules\"][x] = \"error\"\n",
    "                print(\"Globules\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectBlotches(copy, con)\n",
    "                df[\"Blotches\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Blotches\"][x] = \"error\"\n",
    "                print(\"Blotches\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectMilkyRedAreas(copy, con)\n",
    "                df[\"RedAreas\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"RedAreas\"][x] = \"error\"\n",
    "                print(\"RedAreas\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectRosettes(copy, con, state)\n",
    "                df[\"Rosettes\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Rosettes\"][x] = \"error\"\n",
    "                print(\"Rosettes\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectRegressionStructure(copy, con, state)\n",
    "                df[\"RegressionStructure\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"RegressionStructure\"][x] = \"error\"\n",
    "                print(\"RegressionStructure\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectBlueWhiteVeil(copy, con, state)\n",
    "                df[\"BlueWhite\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"BlueWhite\"][x] = \"error\"\n",
    "                print(\"BlueWhite\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectAtypicalNetwork(copy, con, state)\n",
    "                df[\"AtypicalNetwork\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"AtypicalNetwork\"][x] = \"error\"\n",
    "                print(\"AtypicalNetwork\",e)\n",
    "\n",
    "            df[\"Streaks\"][x] = 0\n",
    "            \n",
    "        else:\n",
    "            state = 1\n",
    "            try:\n",
    "                result, amount, perimeter = detectAsymmetry(hullImage, hull)\n",
    "                df[\"Asymmetry\"][x] = result\n",
    "                df[\"Perimeter\"][x] = perimeter\n",
    "                df[\"Asymmetry_Real\"][x] = amount\n",
    "            except Exception as e:\n",
    "                df[\"Asymmetry\"][x] = \"error\"\n",
    "                df[\"Asymmetry_Real\"][x] = \"error\"\n",
    "                print(\"Asymmetry\",e)\n",
    "\n",
    "            try:\n",
    "                result, amount, amountNew = detectBorderIrregularity(con, hull)\n",
    "                df[\"Border\"][x] = result\n",
    "                df[\"Border_Real\"][x] = amount\n",
    "                df[\"Border_New\"][x] = amountNew\n",
    "            except Exception as e:\n",
    "                df[\"Border\"][x] = \"error\"\n",
    "                df[\"Border_Real\"][x] = \"error\"\n",
    "                print(\"Border\",e)\n",
    "\n",
    "            try:\n",
    "                brown, red, blue, white, black, result, count = detectColour(hullImage, hull, state)\n",
    "                df[\"Colour\"][x] = result\n",
    "                df[\"Colour_Real\"][x] = count\n",
    "            except Exception as e:\n",
    "                df[\"Colour\"][x] = \"error\"\n",
    "                df[\"Colour_Real\"][x] = \"error\"\n",
    "                print(\"Colour\",e)\n",
    "\n",
    "            try:\n",
    "                result, amount, width, height = detectDiameter(hullImage, hull)\n",
    "                df[\"Diameter\"][x] = result\n",
    "                df[\"Width\"][x] = width\n",
    "                df[\"Height\"][x] = height\n",
    "                df[\"Diameter_Real\"][x] = amount\n",
    "            except Exception as e:\n",
    "                df[\"Diameter\"][x] = \"error\"\n",
    "                df[\"Diameter_Real\"][x] = \"error\"\n",
    "                print(\"Diameter\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectGlobules(hullImage, hull)\n",
    "                df[\"Globules\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Globules\"][x] = \"error\"\n",
    "                print(\"Globules\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectBlotches(copy, hull)\n",
    "                df[\"Blotches\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Blotches\"][x] = \"error\"\n",
    "                print(\"Blotches\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectMilkyRedAreas(copy, hull)\n",
    "                df[\"RedAreas\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"RedAreas\"][x] = \"error\"\n",
    "                print(\"RedAreas\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectRosettes(hullImage, hull, state)\n",
    "                df[\"Rosettes\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Rosettes\"][x] = \"error\"\n",
    "                print(\"Rosettes\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectRegressionStructure(hullImage, hull, state)\n",
    "                df[\"RegressionStructure\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"RegressionStructure\"][x] = \"error\"\n",
    "                print(\"RegressionStructure\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectBlueWhiteVeil(hullImage, hull, state)\n",
    "                df[\"BlueWhite\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"BlueWhite\"][x] = \"error\"\n",
    "                print(\"BlueWhite\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectAtypicalNetwork(hullImage, hull, state)\n",
    "                df[\"AtypicalNetwork\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"AtypicalNetwork\"][x] = \"error\"\n",
    "                print(\"AtypicalNetwork\",e)\n",
    "\n",
    "            try:\n",
    "                result = detectStreaks(hullImage, hull)\n",
    "                df[\"Streaks\"][x] = result\n",
    "            except Exception as e:\n",
    "                df[\"Streaks\"][x] = \"error\"\n",
    "                print(\"Streaks\",e)\n",
    "            \n",
    "        \n",
    "        count = df[\"Asymmetry\"][x] + df[\"Border\"][x] + df[\"Colour\"][x] + df[\"Diameter\"][x] + df[\"Globules\"][x] + df[\"Blotches\"][x] + df[\"RedAreas\"][x] + df[\"Rosettes\"][x] + df[\"RegressionStructure\"][x] + df[\"BlueWhite\"][x] + df[\"AtypicalNetwork\"][x] + df[\"Streaks\"][x]\n",
    "        print(\"completed\", x, count)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"error\",x)\n",
    "        print(\"Main Loop\",e)\n",
    "        continue\n",
    "\n",
    "df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/HAM_Edited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter','Globules','Blotches','RedAreas','Rosettes','RegressionStructure','BlueWhite','AtypicalNetwork','Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'ABCD_Score', 'Generated_Score', 'Prediction', 'Confidence','Height','Width','Percentage', 'Count']\n",
    "pima = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")\n",
    "pima = pima.iloc[1:]\n",
    "print(pima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/HAM_Edited.csv\")\n",
    "mel_df = df[df.dx != 'mel']\n",
    "mel_df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Datasets/Non-melanoma.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/HAM_Edited.csv\")\n",
    "df = df.drop_duplicates(subset=['lesion_id'], keep='last')\n",
    "df.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Test Data/new_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pickle\n",
    "\n",
    "def classifierVoting(text):\n",
    "\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Border_New', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    dataframe = pd.read_csv(text)\n",
    "    test = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/test_data.csv\")\n",
    "    train = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/training_data.csv\")\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    X = dataframe[feature_cols]\n",
    "    Y = dataframe.True_Status\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=150)\n",
    "    X_train = train[feature_cols]\n",
    "    X_test = test[feature_cols]\n",
    "    y_train = train.True_Status\n",
    "    y_test = test.True_Status\n",
    "    estimators = []\n",
    "    modelLR = LogisticRegression(max_iter=1000)\n",
    "    estimators.append(('logistic', modelLR))\n",
    "    modelSVM = SVC(kernel='linear', probability = True)\n",
    "    estimators.append(('svm', modelSVM))\n",
    "    modelKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    estimators.append(('knn', modelKNN))\n",
    "    modelANN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\n",
    "    estimators.append(('ann', modelANN))\n",
    "    modelAB = AdaBoostClassifier(n_estimators=30, random_state=1)\n",
    "    estimators.append(('adaboost', modelAB))\n",
    "    modelGB = GradientBoostingClassifier(n_estimators=30, random_state=1)\n",
    "    estimators.append(('gradient_boosting', modelGB))\n",
    "    ensemble = VotingClassifier(estimators, voting = 'soft')\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    modelName = 'finalized_model.pkl'\n",
    "    pickle.dump(ensemble, open(modelName, 'wb'))\n",
    "    y_pred = ensemble.predict(X_test)\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred, pos_label=1))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred, pos_label=1))\n",
    "    print(\"F1-Score:\",metrics.f1_score(y_test, y_pred, pos_label=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9183333333333333\n",
      "Precision: 0.9273356401384083\n",
      "Recall: 0.9054054054054054\n",
      "F1-Score: 0.9162393162393163\n"
     ]
    }
   ],
   "source": [
    "classifierVoting(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter','Globules','Blotches','RedAreas','Rosettes','RegressionStructure','BlueWhite','AtypicalNetwork','Streaks', 'Asymmetry_Real', 'Border_Real', 'Border_New', 'Colour_Real', 'Diameter_Real', 'ABCD_Score', 'Generated_Score', 'Prediction', 'Confidence','Height','Width','Percentage', 'Count']\n",
    "dataframe = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")\n",
    "feature_cols = ['image_id', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "dataframe = dataframe.sample(frac=1)\n",
    "dataframe = dataframe.sample(frac=1)\n",
    "dataframe = dataframe.sample(frac=1)\n",
    "X = dataframe[feature_cols]\n",
    "Y = dataframe.True_Status\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=150)\n",
    "\n",
    "for xtr in X_train[\"image_id\"]:\n",
    "    try:\n",
    "        source = \"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Images/Combined Images Dataset/\"+xtr+\".jpg\"\n",
    "        destination = \"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Images/Train/\"+xtr+\".jpg\"\n",
    "        shutil.copyfile(source, destination)\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)\n",
    "for xte in X_test[\"image_id\"]:\n",
    "    try:\n",
    "        source = \"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Images/Combined Images Dataset/\"+xte+\".jpg\"\n",
    "        destination = \"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Images/Test/\"+xte+\".jpg\"\n",
    "        shutil.copyfile(source, destination)\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)\n",
    "\n",
    "test_rows = pd.DataFrame(columns=col_names)\n",
    "train_rows = pd.DataFrame(columns=col_names)\n",
    "\n",
    "# for index,row in dataframe.iterrows():\n",
    "#     print(row)\n",
    "\n",
    "for xtr in X_train[\"image_id\"]:\n",
    "    for index,row in dataframe.iterrows():\n",
    "        if row[\"image_id\"] == xtr:\n",
    "            train_rows = train_rows.append(row, ignore_index = True, sort = False)\n",
    "            \n",
    "for xte in X_test[\"image_id\"]:\n",
    "    for index,row in dataframe.iterrows():\n",
    "        if row[\"image_id\"] == xte:\n",
    "            test_rows = test_rows.append(row, ignore_index = True, sort = False)\n",
    "\n",
    "train_rows.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/training_data.csv\", index=False)\n",
    "test_rows.to_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/test_data.csv\", index=False)\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9183333333333333\n",
      "Precision: 0.9102990033222591\n",
      "Recall: 0.9256756756756757\n",
      "F1-Score: 0.9179229480737018\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "test = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/test_data.csv\")\n",
    "train = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/training_data.csv\")\n",
    "feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "X_train = train[feature_cols]\n",
    "X_test = test[feature_cols]\n",
    "y_train = train.True_Status\n",
    "y_test = test.True_Status\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred, pos_label=1))\n",
    "print(\"F1-Score:\",metrics.f1_score(y_test, y_pred, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "62.15\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "test = pd.read_csv(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/test_data.csv\")\n",
    "X_test = test[feature_cols]\n",
    "row_1 = X_test.iloc[0]\n",
    "# print(row_1[1])\n",
    "arr = []\n",
    "arr.append([])\n",
    "arr[0].append(row_1[0])\n",
    "arr[0].append(row_1[1])\n",
    "arr[0].append(row_1[2])\n",
    "arr[0].append(row_1[3])\n",
    "arr[0].append(row_1[4])\n",
    "arr[0].append(row_1[5])\n",
    "arr[0].append(row_1[6])\n",
    "arr[0].append(row_1[7])\n",
    "arr[0].append(row_1[8])\n",
    "arr[0].append(row_1[9])\n",
    "arr[0].append(row_1[10])\n",
    "arr[0].append(row_1[11])\n",
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(arr)\n",
    "print(y_pred[0])\n",
    "y_pred_proba = loaded_model.predict_proba(arr)[::, 1]\n",
    "level = round(y_pred_proba[0] * 100, 2)\n",
    "print(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
