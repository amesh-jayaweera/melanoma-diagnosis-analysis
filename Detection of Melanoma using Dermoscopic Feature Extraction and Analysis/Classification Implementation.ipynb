{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierSVM(text):\n",
    "    # The columns in the given document\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    # This will ignore the header of the columns when obtaining the values of the dataset\n",
    "#     pima = pima.iloc[1:]\n",
    "    print(len(pima))\n",
    "    # The columns to be considered when training the module\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    # Mixing up the rows in the dataset to make it random (Shuffelling)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    # Assigning the columns in the dataset to he X and Y paramaters\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = SVC(kernel='linear')\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "    \n",
    "def classifierDT(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    pima = pima.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "def classifierNB(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    pima = pima.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = GaussianNB(var_smoothing=2e-9)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "def classifierLR(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    pima = pima.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "def classifierKNN(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    pima = pima.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "def classifierANN(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    pima = pd.read_csv(text)\n",
    "    pima = pima.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    pima = pima.sample(frac=1)\n",
    "    X = pima[feature_cols]\n",
    "    Y = pima.True_Status\n",
    "    model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "def classifierVoting(text):\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    dataframe = pd.read_csv(text)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    X = dataframe[feature_cols]\n",
    "    Y = dataframe.True_Status\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    # create the sub models\n",
    "    estimators = []\n",
    "    modelLR = LogisticRegression(max_iter=1000)\n",
    "    estimators.append(('logistic', modelLR))\n",
    "    modelSVM = SVC(kernel='linear')\n",
    "    estimators.append(('svm', modelSVM))\n",
    "    modelKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    estimators.append(('knn', modelKNN))\n",
    "    modelANN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\n",
    "    estimators.append(('ann', modelANN))\n",
    "    modelAB = AdaBoostClassifier(n_estimators=30, random_state=1)\n",
    "    estimators.append(('adaboost', modelAB))\n",
    "    modelGB = GradientBoostingClassifier(n_estimators=30, random_state=1)\n",
    "    estimators.append(('gradient_boosting', modelGB))\n",
    "    # create the ensemble model\n",
    "    ensemble = VotingClassifier(estimators)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(ensemble, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "\n",
    "    \n",
    "def classifierGradientBoosting(text):\n",
    "\n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    dataframe = pd.read_csv(text)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    X = dataframe[feature_cols]\n",
    "    Y = dataframe.True_Status\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    model = GradientBoostingClassifier(n_estimators=30, random_state=1)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))\n",
    "    \n",
    "def classifierAdaBoost(text):\n",
    "    \n",
    "    col_names = ['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization', 'True_Status', 'Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks', 'Asymmetry_Real', 'Border_Real', 'Colour_Real', 'Diameter_Real', 'Height', 'Width', 'Percentage']\n",
    "    dataframe = pd.read_csv(text)\n",
    "    dataframe = dataframe.iloc[1:]\n",
    "    feature_cols = ['Asymmetry', 'Border', 'Colour', 'Diameter', 'Globules', 'Blotches', 'RedAreas', 'Rosettes', 'RegressionStructure', 'BlueWhite', 'AtypicalNetwork', 'Streaks']\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    X = dataframe[feature_cols]\n",
    "    Y = dataframe.True_Status\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    model = AdaBoostClassifier(n_estimators=30, random_state=1)\n",
    "    scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score, pos_label=1),\n",
    "               'recall' : make_scorer(recall_score, pos_label=1), \n",
    "               'f1_score' : make_scorer(f1_score, pos_label=1)}\n",
    "    results = model_selection.cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    print(\"Accuracy\", np.mean(results['test_accuracy']))\n",
    "    print(\"Precision\", np.mean(results['test_precision']))\n",
    "    print(\"Recall\", np.mean(results['test_recall']))\n",
    "    print(\"F1 Score\", np.mean(results['test_f1_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Accuracy 0.909\n",
      "Precision 0.9011438992690703\n",
      "Recall 0.9165916080720946\n",
      "F1 Score 0.9083872009741807\n"
     ]
    }
   ],
   "source": [
    "classifierSVM(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9099698492462311\n",
      "Precision 0.9001292181922989\n",
      "Recall 0.9212152216858016\n",
      "F1 Score 0.910392733598022\n"
     ]
    }
   ],
   "source": [
    "classifierANN(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8964597989949749\n",
      "Precision 0.9005463440761738\n",
      "Recall 0.8922489154903224\n",
      "F1 Score 0.895686022674717\n"
     ]
    }
   ],
   "source": [
    "classifierKNN(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9109472361809046\n",
      "Precision 0.9075954335545694\n",
      "Recall 0.9153791584017081\n",
      "F1 Score 0.911113665517871\n"
     ]
    }
   ],
   "source": [
    "classifierLR(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8834422110552763\n",
      "Precision 0.9285375617261529\n",
      "Recall 0.8312714908998124\n",
      "F1 Score 0.8768133407127792\n"
     ]
    }
   ],
   "source": [
    "classifierDT(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8744447236180903\n",
      "Precision 0.9399236381299529\n",
      "Recall 0.8008500939701438\n",
      "F1 Score 0.8641828174842452\n"
     ]
    }
   ],
   "source": [
    "classifierNB(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9154597989949748\n",
      "Precision 0.8983654884716262\n",
      "Recall 0.9376475665700005\n",
      "F1 Score 0.9171213651162555\n"
     ]
    }
   ],
   "source": [
    "classifierAdaBoost(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9064422110552766\n",
      "Precision 0.9185127883088441\n",
      "Recall 0.8942501933462473\n",
      "F1 Score 0.9058376497043866\n"
     ]
    }
   ],
   "source": [
    "classifierGradientBoosting(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9094497487437186\n",
      "Precision 0.9031608739487187\n",
      "Recall 0.9174137158435978\n",
      "F1 Score 0.9097364182341264\n"
     ]
    }
   ],
   "source": [
    "classifierVoting(\"/users/chinthaka_jayatilake/Documents/Research Work/Final Presentation/Dataset Sheets/combined_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
